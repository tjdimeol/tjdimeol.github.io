<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Computer Vision Project 2 - Image Homography and Warping</title>
    <style>
        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            max-width: 900px;
            margin: 40px auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
            background-color: #fafafa;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            border-bottom: 2px solid #333;
            padding-bottom: 20px;
        }

        h1 {
            font-size: 2.2em;
            margin-bottom: 10px;
        }

        .author-info {
            font-size: 1.1em;
            color: #666;
        }

        h2 {
            font-size: 1.8em;
            margin-top: 40px;
            margin-bottom: 20px;
            color: #2c3e50;
            border-bottom: 1px solid #ddd;
            padding-bottom: 10px;
        }

        h3 {
            font-size: 1.4em;
            margin-top: 30px;
            margin-bottom: 15px;
            color: #34495e;
        }

        p {
            margin-bottom: 15px;
            text-align: justify;
        }

        .figure {
            margin: 30px 0;
            text-align: center;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }

        .figure-caption {
            margin-top: 15px;
            font-style: italic;
            color: #555;
            font-size: 0.95em;
        }

        .gif-figure {
            margin: 30px 0;
            text-align: center;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.15);
            border: 2px solid #3498db;
        }

        ul {
            margin-left: 20px;
        }

        li {
            margin-bottom: 8px;
        }

        footer {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #777;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <header>
        <h1>Report 2</h1>
        <h2 style="border:none; margin-top:10px;">Project 2: Image Homography and Warping</h2>
        <div class="author-info">
            <p><strong>TJ DiMeola</strong><br>
            Course: Computer Vision CSCI 581<br>
            Instructor: Dr. Hawk Wang<br>
            Date: October 19, 2025</p>
        </div>
    </header>

    <section id="project-objective">
        <h2>Project Objective</h2>
        <p>In this project, geometric transformation concepts will be applied to carry out image rectification and explore creative applications of image homography. The goal is to understand how 2D transformations can recover fronto-parallel views of planar surfaces and be used in real-world applications such as document scanning or panoramic stitching.</p>
    </section>

    <section id="part1">
        <h2>Part 1: Image Homography Estimation</h2>
        <p>Implement homography estimation and image warping to rectify an input image containing a planar surface (e.g., a document, a poster, or a road sign) captured at an angle.</p>

        <h3>Tasks:</h3>
        <p><strong>1.</strong> Manually select 4+ point correspondences between the original image and a target rectangular region.</p>

        <p><strong>2.</strong> Estimate the homography matrix H (e.g., using the DLT algorithm). The Direct Linear Transform (DLT) Algorithm estimates H from point correspondences between two images. A minimum of 4 point correspondences is selected. Note that the more points the better, making an overdetermined system, solved with least squares.</p>

        <p><strong>Steps:</strong></p>
        <ul>
            <li>Set up the equation:
                <br>x1 = , y1 = , x2 = , y2 = ,x3 = , y3 = , x4 = , y4 =
                <br>x1* = , y1* = , x2* = , y2* = ,x3* = , y3* = , x4* = , y4* =
            </li>
            <li>For each correspondence (x, y) → (x', y'), we can write:
                <br>x' = (h11*x + h12*y + h13) / (h31*x + h32*y + h33)
                <br>y' = (h21*x + h22*y + h23) / (h31*x + h32*y + h33)
            </li>
            <li>Then cross-multiplying to eliminate the denominator:
                <br>h11*x + h12*y + h13 - h31*x*x' - h32*y*x' - h33*x' = 0
                <br>h21*x + h22*y + h23 - h31*x*y' - h32*y*y' - h33*y' = 0
            </li>
            <li>Build matrix A: For n point correspondences, create a 2n × 9 matrix A where each point gives 2 rows:
                <br>[-x -y -1 0 0 0 x*x' y*x' x']
                <br>[ 0 0 0 -x -y -1 x*y' y*y' y']
                <br><br>The homography vector h = [h11, h12, h13, h21, h22, h23, h31, h32, h33]^T satisfies: Ah = 0
            </li>
            <li>Solve using SVD: Since there are more equations than unknowns (overdetermined), use Singular Value Decomposition (SVD):
                <br>A = U Σ V^T
                <br><br>The solution h is the last row of V^T (or equivalently, the last column of V) (corresponding to the smallest singular value).
            </li>
            <li>Reshape the 9-element vector h into the 3×3 homography matrix H.</li>
            <li>Normalize before computing H (optional but better stability):
                <br>- Translate points so their centroid is at origin
                <br>- Scale so average distance from origin is √2
                <br>- Compute H normalized
                <br>- Denormalize: H = T_dest^(-1) × H_normalized × T_src
            </li>
            <li>Warp the original image using inverse mapping to obtain a rectified (fronto-parallel) view.</li>
            <li>Visualize before/after results.</li>
        </ul>

        <h3>Deliverables:</h3>
        <p>(a) Visualization of correspondences.</p>
        <p>(b) Original image and rectified output.</p>

        <div class="figure">
            <img src="images/homography_small.jpg" alt="Homography Visualization">
            <div class="figure-caption"><strong>Figure 1:</strong> Visualization of point correspondences and rectification process.</div>
        </div>

        <p><strong>(c) Brief discussion describing how homography enables rectification.</strong></p>
        <p>In some ways, homography is intuitive: If you select four (or more) points in one coordinate system in which the points are not orthogonal, and then translate them to another coordinate system in which they <em>are</em> orthogonal, you could probably figure out the math (figure out the relationships in space between the points, calculate the angles, etc.). Homography provides a clear "recipe" for this translation, and in particular, the DLT algorithm.</p>
    </section>

    <section id="part2">
        <h2>Part 2: Creative Application (Exploration and Extension)</h2>
        <p>Use your homography implementation creatively to demonstrate a real-world or artistic application.</p>

        <h3>Requirements:</h3>
        <ul>
            <li>Use your homography code from Part 1.</li>
            <li>Describing your idea, what worked well, and any challenges.</li>
            <li>You are encouraged to be creative and propose your own ideas.</li>
        </ul>

        <h3>Experiment: Cover the walls and doors of a hallway with colorful wallpaper.</h3>

        <h3>Tasks:</h3>
        <ul>
            <li>Create a utility that would help select points on any section of the wall (sort of like a lasso selection tool in GIMP or Photoshop).</li>
            <li>Take a reasonable photo of the hallway</li>
            <li>For each selected wall section, warp a texture using homography to fit the wall's perspective.</li>
            <li>Repeat for all wall/ceiling/door sections of interest.</li>
        </ul>

        <div class="figure">
            <img src="images/texturedHall_small.jpg" alt="Textured Hallway Progression">
            <div class="figure-caption"><strong>Figure 2:</strong> Progressive hallway texturing showing artistic texture application to walls, ceiling, doors, and floor.</div>
        </div>

        <h3>Discussion</h3>
        <p>My original idea was to take photos of each wall of a hallway and stitch them together using homographic control points. However, I could not, within the confined space, obtain sufficient overlap to build the ~50% overlap needed to fully unwrap the walls.</p>

        <p>My fallback then was to take a single photo of the hall (top left above) and figure out a way to texture each wall.</p>

        <p>I definitely did not want to hand-calculate each control point for every part of the wall, so I used a utility to select as many points as were required to capture the surfaces of walls, ceiling, doors, and floor.</p>

        <p>For each surface and set of points, the homography was then calculated and the texture (found online) applied.</p>

        <p>This was very interesting because although the points in the hall for each wall were obvious (corners, etc.), the texture points had to be selected blindly. But just as long as they matched the same number of control points as on the walls, this worked pretty well and made really interesting warpage of the textures. I did have to add one section where the wall just got too complex. For fun this was fine. For real, this might have been tough.</p>
    </section>

    <section id="part3">
        <h2>Part 3: Warping Comparison</h2>
        <p>Compare triangular mesh warping and thin-plate spline (TPS) warping.</p>

        <h3>Tasks:</h3>
        <ul>
        <li>Implement or use available routines for both warping methods.</p>
        <li>Apply both to the same input (e.g., facial landmarks, grid deformation, or a planar surface).</p>
        <li>Compare visually and discuss differences in smoothness, continuity, and computational cost.</p>
        </ul>
        
        <h3>Deliverables:</h3>
        <p>Visual comparison (side-by-side outputs).</p>

        <h3>Discussion: Mesh warping vs TPS warping</h3>

        <p><strong>• Mesh Warping</strong> uses Delaunay triangulation to partition the image into non-overlapping triangles, then warps each triangle independently using affine transformations. The triangles are created by connecting control points such that no point lies inside the circumcircle of any triangle - this maximizes the minimum angle of all triangles, avoiding long, skinny triangles that would create artifacts. For each triangle, an affine transformation is carried out:</p>

        <p style="text-align: center;">
            [x'] &nbsp;&nbsp; [a &nbsp;b &nbsp;c] &nbsp;[x]<br>
            [y'] = [d &nbsp;e &nbsp;f] &nbsp;[y]<br>
            [1 ] &nbsp;&nbsp; [0 &nbsp;0 &nbsp;1] &nbsp;[1]
        </p>

        <p>These 6 degrees of freedom ensure that:</p>
        <ul>
            <li>Straight lines remain straight</li>
            <li>Parallel lines remain parallel (within each triangle)</li>
            <li>Ratios of distances along lines</li>
        </ul>

        <p>The transformation is computed from the three vertex correspondences by:</p>
        <ul>
            <li>Mapping source triangle vertices to destination triangle vertices</li>
            <li>Solving for the 2×3 affine matrix</li>
            <li>Applying the transformation only within that triangle's region</li>
        </ul>

        <p>The computed triangular mesh is overlaid on the image and each triangle acts as a local coordinate system - moving one control point only affects the triangles connected to it, not the entire image. Piecewise the mesh is smooth but there is potential for discontinuities at triangle edges where different affine transforms meet - this is called C⁰ continuity. Since each triangle is warped independently huge deformations are unlikely.</p>

        <p><strong>• TPS Warping</strong> is a radial basis function (RBF):</p>
        <p style="text-align: center;">φ(r) = r² log(r)</p>

        <p>where r is the distance from a control point. For 2D image warping, the transformation for each coordinate (x or y) is:</p>
        <p style="text-align: center;">f(x, y) = a₁ + a₂x + a₃y + Σ wᵢ · φ(||pᵢ - p||)</p>

        <p>where:</p>
        <ul>
            <li>The first part (a₁ + a₂x + a₃y) is an affine transformation (linear/polynomial part)</li>
            <li>The 2nd part is a weighted sum of radial basis functions centered at each control point pᵢ</li>
            <li>||pᵢ - p|| is the Euclidean distance from point p to control point pᵢ</li>
            <li>wᵢ are weights determined by solving a system of equations to satisfy the control point constraints.</li>
        </ul>

        <p>Unlike mesh warping, TPS warping, r² log(r), grows slowly, creating smooth deformations, but since they are global, potentially subject to massive deformation.</p>

        <h3>Experimentation:</h3>
        <p>To test both mesh and TPS warping, I decided to see how adding specific control points to an image of a heart, could cause deformation such that the image would be contracted. The overall goal was to see if the heart could look like it was beating.</p>

        <p>The first attempt (below), 6 control points were placed around the heart in a irregular circle. In triangular mesh warping, this basically squished the entire heart to nothingness, while TPS turned the heart into a ring.</p>

        <div class="figure">
            <img src="images/warpedHeartsmall1.jpg" alt="Attempt 1 - Ring Pattern">
            <div class="figure-caption"><strong>Figure 3:</strong> First attempt with 6 control points in circular pattern showing extreme deformations.</div>
        </div>

        <p>For the second attempt (below), more points (12) to form two rings, but in a zig zag fashion so that every second point would "pull" the part in. This sort of worked, but in both methods the heart was deformed. The point placement needed more precision to avoid extreme deformation.</p>

        <div class="figure">
            <img src="images/warpedHeartSmall2.jpg" alt="Attempt 2 - Zig Zag Pattern">
            <div class="figure-caption"><strong>Figure 4:</strong> Second attempt with 12 control points in zig-zag pattern showing improved but still deformed results.</div>
        </div>

        <p>The third attempt (below), retained 12 points, but care was taken to make the rings accurate, and follow the anatomy of the heart.</p>

        <div class="figure">
            <img src="images/warping_comparison.jpg" alt="Attempt 3 - Anatomical">
            <div class="figure-caption"><strong>Figure 5:</strong> Third attempt with 12 carefully placed anatomical control points showing realistic contraction.</div>
        </div>

        <p>The mesh warp method resulted in a heart image that was sufficiently deformed such that it might work well as a "beat" of the heart. By putting the two images together to create a gif, the original idea to mimic a beating heart did work.</p>

        <div class="gif-figure">
            <img src="images/heart_beat_SLOW.gif" alt="Beating Heart Animation">
            <div class="figure-caption"><strong>Figure 6:</strong> Animated beating heart created using triangular mesh warping with interpolated control points.</div>
        </div>

        <h3>Analysis:</h3>
        <p>For smoothness and continuity, TPS is better. It is fully smooth and globally continuous whereas, triangular mesh leaves visible seams at triangle boundaries. Meshes are piecewise continuous (within triangles), but not across them.</p>

        <p>TPS' global approach means that a pattern that is global (like my ring of points), could end up completely redefining the structure (but smoothly). This global sensitivity extends to outlier control points - a single poorly-placed point can affect the entire image, as demonstrated by the ring effect in attempt 1, above. The mesh approach maintains more local structure so that it is less likely to result in a sudden weird shape.</p>

        <p>With respect to computational cost, mesh is faster because each triangle is processed independently, while TPS takes more time in order to carry out global optimization.</p>

        <p>The choice depends on the application: triangular mesh is preferable for fast, local deformations with acceptable discontinuities (e.g., real-time applications), while TPS is ideal when smooth, natural-looking deformations are critical (e.g., medical imaging, facial morphing).</p>
    </section>

    <footer>
        <p>Computer Vision CSCI 581 - Project 2<br>
        TJ DiMeola | University of Mississippi | October 2025</p>
    </footer>
</body>
</html>
